{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/serge/Documents/food/Food_project\n"
     ]
    }
   ],
   "source": [
    "cd ~/Documents/food/Food_project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1\n"
     ]
    }
   ],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "%env CUDA_VISIBLE_DEVICES=0,1\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "set_session(sess)\n",
    "tf.random.set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_directory = \"./Food_photos_copy\"\n",
    "fine_to_coarse = pd.read_csv(\"fine_to_coarse.csv\",encoding = \"utf-8\")\n",
    "coarse_labels = fine_to_coarse[\"Coarse names\"]\n",
    "coarse_labels = list(coarse_labels.to_numpy())\n",
    "\n",
    "data = pd.read_pickle(\"./data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salad',\n",
       " 'Soup',\n",
       " 'Sandwich',\n",
       " 'Wrap',\n",
       " 'Drink',\n",
       " 'Dressing',\n",
       " 'Fruit',\n",
       " 'Veggies',\n",
       " 'Meats',\n",
       " 'Pastry',\n",
       " 'Rice',\n",
       " 'Sushi',\n",
       " 'Desserts/Sweet snacks',\n",
       " 'Salty snacks',\n",
       " 'Cereal/Cereal bar',\n",
       " 'Pasta',\n",
       " 'Yogurt',\n",
       " 'Fried sides',\n",
       " 'Pizza',\n",
       " 'Burger',\n",
       " 'Bread',\n",
       " 'Cheese']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>fine labels</th>\n",
       "      <th>coarse labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C040.HT 2015-06-05 130853 C.png</td>\n",
       "      <td>[Green beans with cherry tomatoes, Cornbread M...</td>\n",
       "      <td>[Veggies, Pasta, Desserts/Sweet snacks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A084.GK 2015-07-23 122234 A.png</td>\n",
       "      <td>[Do Not Use Build a Chicken Salad, Glass Coke ...</td>\n",
       "      <td>[Sandwich, Fried sides, Bread, Salad, Drink]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C060.PS 2016-06-03 132753 C.png</td>\n",
       "      <td>[Build a Salad, Spring Mix Lettuce, Jalapenos,...</td>\n",
       "      <td>[Salad, Dressing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B113.TA 2015-08-13 132111 B.png</td>\n",
       "      <td>[Meatballs, Roll, Just Cookies - White Chocola...</td>\n",
       "      <td>[Dressing, Desserts/Sweet snacks, Pastry, Meats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C017.WA 2016-05-10 123024 C.png</td>\n",
       "      <td>[Build a Self Serve, Whole Banana, Fruit Salad]</td>\n",
       "      <td>[Fruit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  \\\n",
       "0  C040.HT 2015-06-05 130853 C.png   \n",
       "1  A084.GK 2015-07-23 122234 A.png   \n",
       "2  C060.PS 2016-06-03 132753 C.png   \n",
       "3  B113.TA 2015-08-13 132111 B.png   \n",
       "4  C017.WA 2016-05-10 123024 C.png   \n",
       "\n",
       "                                         fine labels  \\\n",
       "0  [Green beans with cherry tomatoes, Cornbread M...   \n",
       "1  [Do Not Use Build a Chicken Salad, Glass Coke ...   \n",
       "2  [Build a Salad, Spring Mix Lettuce, Jalapenos,...   \n",
       "3  [Meatballs, Roll, Just Cookies - White Chocola...   \n",
       "4    [Build a Self Serve, Whole Banana, Fruit Salad]   \n",
       "\n",
       "                                      coarse labels  \n",
       "0           [Veggies, Pasta, Desserts/Sweet snacks]  \n",
       "1      [Sandwich, Fried sides, Bread, Salad, Drink]  \n",
       "2                                 [Salad, Dressing]  \n",
       "3  [Dressing, Desserts/Sweet snacks, Pastry, Meats]  \n",
       "4                                           [Fruit]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train & val\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.15,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5250 images belonging to 22 classes.\n",
      "Found 1312 images belonging to 22 classes.\n",
      "Found 1159 images belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=20, \n",
    "                                   zoom_range=[1.1,1.6],\n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip = True,\n",
    "                                  validation_split=0.20)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train, directory=im_directory, x_col='name', y_col='coarse labels',subset=\"training\", target_size=(224, 224), color_mode='rgb', classes=coarse_labels, class_mode='categorical', batch_size=32, shuffle=True, seed=123, save_to_dir=None, save_prefix='', save_format='png', interpolation='nearest', drop_duplicates=True)\n",
    "val_generator = train_datagen.flow_from_dataframe(train, directory=im_directory, x_col='name', y_col='coarse labels',subset=\"validation\", target_size=(224, 224), color_mode='rgb', classes=coarse_labels, class_mode='categorical', batch_size=1, shuffle=False, seed=123, save_to_dir=None, save_prefix='', save_format='png', interpolation='nearest', drop_duplicates=True)\n",
    "test_generator = test_datagen.flow_from_dataframe(test, directory=im_directory, x_col='name', y_col='coarse labels', target_size=(224, 224), color_mode='rgb', classes=coarse_labels, class_mode='categorical', batch_size=1, shuffle=False, seed=123, save_to_dir=None, save_prefix='', save_format='png', subset=None, interpolation='nearest', drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/serge/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "from keras import Model\n",
    "from keras.layers import Dense\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "N_classes = 22\n",
    "mobilenet = MobileNetV2(include_top=False, weights=None, input_tensor=None, input_shape=(224,224,3), pooling='avg', classes=N_classes)\n",
    "\n",
    "x = mobilenet.layers[-1].output\n",
    "fc = Dense(N_classes,activation='sigmoid')(x)\n",
    "model = Model(inputs=mobilenet.input, outputs=fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 22)           28182       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,286,166\n",
      "Trainable params: 2,252,054\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from time import time\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "name = \"mobilenet_dense\"\n",
    "checkpointer = ModelCheckpoint(filepath=os.path.join(\"models\",name+\"_weights.hdf5\"), \n",
    "                               monitor = 'val_loss',\n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Metrics(tf.keras.callbacks.Callback):\n",
    "    \n",
    "#     def __init__(self, val_data, batch_size = 1):\n",
    "#         super().__init__()\n",
    "#         self.validation_data = val_data\n",
    "#         self.batch_size = batch_size\n",
    "    \n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         print(self.validation_data)\n",
    "#         self.val_f1s = []\n",
    "#         self.val_recalls = []\n",
    "#         self.val_precisions = []\n",
    "#         self.mean_auc_per_class = None\n",
    "        \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         batches = len(self.validation_data)\n",
    "#         total = batches * self.batch_size\n",
    "\n",
    "#         self.validation_data.reset()\n",
    "#         val_pred = self.model.predict_generator(self.validation_data,steps = len(self.validation_data))\n",
    "#         val_true = [[True if i in row else False for i in range(22)] for row in self.validation_data.classes]\n",
    "#         val_true = np.array(val_true)\n",
    "#         aucs = []\n",
    "#         for i in range(22):\n",
    "#             y_true = val_true[:,i]\n",
    "#             y_score = val_pred[:,i]\n",
    "#             aucs.append(roc_auc_score(y_true,y_score))\n",
    "            \n",
    "#         self.mean_auc_per_class = np.mean(aucs)\n",
    "#         print(\"Mean per-class AUC:{}\".format(self.mean_auc_per_class))\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/serge/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7f3a2052bef0>\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 203s 1s/step - loss: 0.3430 - acc: 0.8608 - val_loss: 1.0030 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.00300, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.5139397102163411\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.3143 - acc: 0.8713 - val_loss: 1.1163 - val_acc: 0.7623\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.00300\n",
      "Mean per-class AUC:0.5121182076453548\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 193s 1s/step - loss: 0.2999 - acc: 0.8781 - val_loss: 0.9756 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.00300 to 0.97562, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.5218013166230718\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2900 - acc: 0.8818 - val_loss: 0.9888 - val_acc: 0.7492\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97562\n",
      "Mean per-class AUC:0.5204046702959642\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2888 - acc: 0.8815 - val_loss: 0.9389 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.97562 to 0.93887, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.5173631361614963\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2880 - acc: 0.8816 - val_loss: 1.1597 - val_acc: 0.7566\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5074412748040249\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2824 - acc: 0.8854 - val_loss: 1.0984 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5069446735789488\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2779 - acc: 0.8872 - val_loss: 1.4184 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5091804119888703\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 193s 1s/step - loss: 0.2725 - acc: 0.8895 - val_loss: 1.4886 - val_acc: 0.7249\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5096820868074263\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 193s 1s/step - loss: 0.2697 - acc: 0.8912 - val_loss: 1.1815 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5129097623964807\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2640 - acc: 0.8932 - val_loss: 0.9653 - val_acc: 0.8069\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5169989835953396\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2584 - acc: 0.8966 - val_loss: 1.2448 - val_acc: 0.7772\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5095741474820403\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2546 - acc: 0.8959 - val_loss: 1.1160 - val_acc: 0.7873\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5183071800746648\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2525 - acc: 0.8978 - val_loss: 1.7049 - val_acc: 0.7616\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5094092790922122\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2505 - acc: 0.8991 - val_loss: 1.6741 - val_acc: 0.7383\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5174225929982484\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2463 - acc: 0.9008 - val_loss: 1.1103 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5315051323481259\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2426 - acc: 0.9022 - val_loss: 1.2319 - val_acc: 0.7943\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5255579803059359\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 193s 1s/step - loss: 0.2416 - acc: 0.9020 - val_loss: 1.5268 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5106963388273996\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2416 - acc: 0.9026 - val_loss: 1.7413 - val_acc: 0.7602\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.93887\n",
      "Mean per-class AUC:0.5021347604631218\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2377 - acc: 0.9037 - val_loss: 0.9310 - val_acc: 0.7968\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.93887 to 0.93098, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.5330067116153684\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2356 - acc: 0.9053 - val_loss: 0.9005 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.93098 to 0.90055, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.5502177185912264\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2341 - acc: 0.9048 - val_loss: 0.9221 - val_acc: 0.7914\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.90055\n",
      "Mean per-class AUC:0.5471713648339877\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2287 - acc: 0.9080 - val_loss: 1.0864 - val_acc: 0.7719\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.90055\n",
      "Mean per-class AUC:0.5564530204115445\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2272 - acc: 0.9078 - val_loss: 1.2885 - val_acc: 0.7403\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.90055\n",
      "Mean per-class AUC:0.5589098872752936\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2286 - acc: 0.9082 - val_loss: 0.8702 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.90055 to 0.87015, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.5674831901280093\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2257 - acc: 0.9076 - val_loss: 0.7239 - val_acc: 0.7877\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.87015 to 0.72386, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6037926936436381\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2252 - acc: 0.9100 - val_loss: 1.1389 - val_acc: 0.7658\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.72386\n",
      "Mean per-class AUC:0.5559646061025855\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2234 - acc: 0.9097 - val_loss: 0.7363 - val_acc: 0.8069\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.72386\n",
      "Mean per-class AUC:0.5647862179576321\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2194 - acc: 0.9108 - val_loss: 0.7206 - val_acc: 0.8137\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.72386 to 0.72065, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.5663333309495631\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2156 - acc: 0.9128 - val_loss: 0.9887 - val_acc: 0.7959\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.5785670573944607\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2179 - acc: 0.9123 - val_loss: 1.1955 - val_acc: 0.8136\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.5372201938385658\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2145 - acc: 0.9140 - val_loss: 0.8616 - val_acc: 0.8026\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.5771658583166676\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2114 - acc: 0.9147 - val_loss: 0.7496 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.6004611958886515\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 191s 1s/step - loss: 0.2123 - acc: 0.9130 - val_loss: 0.8666 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.5606023338589627\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2093 - acc: 0.9154 - val_loss: 0.8983 - val_acc: 0.8164\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.5932770965407287\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2103 - acc: 0.9145 - val_loss: 0.7796 - val_acc: 0.8159\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.6126025345663513\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2081 - acc: 0.9158 - val_loss: 0.8672 - val_acc: 0.8231\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.5980546024501531\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2120 - acc: 0.9140 - val_loss: 0.7808 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.5634801368266507\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2060 - acc: 0.9167 - val_loss: 0.8806 - val_acc: 0.8187\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.5749855643701173\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2058 - acc: 0.9165 - val_loss: 0.8991 - val_acc: 0.8057\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.6055375234386943\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2023 - acc: 0.9180 - val_loss: 0.9414 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.72065\n",
      "Mean per-class AUC:0.569022885790609\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.2011 - acc: 0.9184 - val_loss: 0.6590 - val_acc: 0.8253\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.72065 to 0.65901, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6041821867975142\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1975 - acc: 0.9192 - val_loss: 0.7253 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.65901\n",
      "Mean per-class AUC:0.5706173905580502\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1986 - acc: 0.9193 - val_loss: 0.7634 - val_acc: 0.8196\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.65901\n",
      "Mean per-class AUC:0.5686820269766049\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1932 - acc: 0.9213 - val_loss: 0.7448 - val_acc: 0.8019\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.65901\n",
      "Mean per-class AUC:0.6122599249745269\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.2038 - acc: 0.9169 - val_loss: 0.5375 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.65901 to 0.53746, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6245751164059373\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1964 - acc: 0.9199 - val_loss: 0.5159 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.53746 to 0.51590, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6221334096871735\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1932 - acc: 0.9217 - val_loss: 0.4804 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.51590 to 0.48035, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6430203497464014\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1910 - acc: 0.9220 - val_loss: 0.4381 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.48035 to 0.43809, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6028385832207437\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1881 - acc: 0.9233 - val_loss: 0.4417 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.43809\n",
      "Mean per-class AUC:0.6269159396903853\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.1895 - acc: 0.9230 - val_loss: 0.4444 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.43809\n",
      "Mean per-class AUC:0.6498897046594557\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1960 - acc: 0.9207 - val_loss: 0.6457 - val_acc: 0.8074\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.43809\n",
      "Mean per-class AUC:0.6243830403047315\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1845 - acc: 0.9244 - val_loss: 0.5206 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.43809\n",
      "Mean per-class AUC:0.6102525738940296\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1857 - acc: 0.9239 - val_loss: 0.4151 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.43809 to 0.41508, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6565457587856046\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1797 - acc: 0.9269 - val_loss: 0.3578 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.41508 to 0.35777, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6531939953717067\n",
      "Epoch 56/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1818 - acc: 0.9252 - val_loss: 0.4398 - val_acc: 0.8447\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.35777\n",
      "Mean per-class AUC:0.6191963916357867\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1798 - acc: 0.9271 - val_loss: 0.3776 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.35777\n",
      "Mean per-class AUC:0.6659318449190521\n",
      "Epoch 58/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1797 - acc: 0.9260 - val_loss: 0.3228 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.35777 to 0.32276, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6710351230895371\n",
      "Epoch 59/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1788 - acc: 0.9270 - val_loss: 0.3308 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.32276\n",
      "Mean per-class AUC:0.6870527133035796\n",
      "Epoch 60/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1765 - acc: 0.9274 - val_loss: 0.7240 - val_acc: 0.7881\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.32276\n",
      "Mean per-class AUC:0.6253930923594275\n",
      "Epoch 61/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.1762 - acc: 0.9272 - val_loss: 0.3666 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.32276\n",
      "Mean per-class AUC:0.6728223256673068\n",
      "Epoch 62/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.1755 - acc: 0.9279 - val_loss: 0.3423 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.32276\n",
      "Mean per-class AUC:0.6920350866569821\n",
      "Epoch 63/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1734 - acc: 0.9293 - val_loss: 0.3873 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.32276\n",
      "Mean per-class AUC:0.6480932876937373\n",
      "Epoch 64/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1800 - acc: 0.9254 - val_loss: 0.3818 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.32276\n",
      "Mean per-class AUC:0.6362649962251897\n",
      "Epoch 65/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1766 - acc: 0.9275 - val_loss: 0.3024 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.32276 to 0.30243, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6710991269377358\n",
      "Epoch 66/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1699 - acc: 0.9297 - val_loss: 0.3527 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.30243\n",
      "Mean per-class AUC:0.6867066362850524\n",
      "Epoch 67/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1745 - acc: 0.9279 - val_loss: 0.4048 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.30243\n",
      "Mean per-class AUC:0.6737932387595327\n",
      "Epoch 68/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1761 - acc: 0.9286 - val_loss: 0.3973 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.30243\n",
      "Mean per-class AUC:0.6233996319132559\n",
      "Epoch 69/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1719 - acc: 0.9299 - val_loss: 0.3571 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.30243\n",
      "Mean per-class AUC:0.660285758934556\n",
      "Epoch 70/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1736 - acc: 0.9296 - val_loss: 0.3808 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.30243\n",
      "Mean per-class AUC:0.6653969853552043\n",
      "Epoch 71/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1659 - acc: 0.9315 - val_loss: 0.4401 - val_acc: 0.8369\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.30243\n",
      "Mean per-class AUC:0.6746870057071637\n",
      "Epoch 72/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1696 - acc: 0.9313 - val_loss: 0.3810 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.30243\n",
      "Mean per-class AUC:0.6623622969409794\n",
      "Epoch 73/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1674 - acc: 0.9317 - val_loss: 0.2911 - val_acc: 0.8946\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.30243 to 0.29108, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6904109745418764\n",
      "Epoch 74/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1601 - acc: 0.9341 - val_loss: 0.2841 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.29108 to 0.28411, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.6987389692727767\n",
      "Epoch 75/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1665 - acc: 0.9316 - val_loss: 0.2633 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.28411 to 0.26335, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.722479900616968\n",
      "Epoch 76/200\n",
      "164/164 [==============================] - 192s 1s/step - loss: 0.1686 - acc: 0.9308 - val_loss: 0.3334 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.26335\n",
      "Mean per-class AUC:0.6749997963568952\n",
      "Epoch 77/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1613 - acc: 0.9336 - val_loss: 0.2558 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.26335 to 0.25577, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.7301261829379547\n",
      "Epoch 78/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1635 - acc: 0.9326 - val_loss: 0.3296 - val_acc: 0.8803\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.25577\n",
      "Mean per-class AUC:0.6925540438838701\n",
      "Epoch 79/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1568 - acc: 0.9359 - val_loss: 0.3344 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.25577\n",
      "Mean per-class AUC:0.6587060811382517\n",
      "Epoch 80/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1563 - acc: 0.9363 - val_loss: 0.2979 - val_acc: 0.8954\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.25577\n",
      "Mean per-class AUC:0.657289632622728\n",
      "Epoch 81/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1548 - acc: 0.9363 - val_loss: 0.3051 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.25577\n",
      "Mean per-class AUC:0.6773714166157263\n",
      "Epoch 82/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1556 - acc: 0.9358 - val_loss: 0.2526 - val_acc: 0.9021\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.25577 to 0.25261, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.691148213686851\n",
      "Epoch 83/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1526 - acc: 0.9374 - val_loss: 0.2795 - val_acc: 0.9027\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.25261\n",
      "Mean per-class AUC:0.7066972676362885\n",
      "Epoch 84/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1555 - acc: 0.9356 - val_loss: 0.2645 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.25261\n",
      "Mean per-class AUC:0.7193287570664496\n",
      "Epoch 85/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1545 - acc: 0.9358 - val_loss: 0.3017 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.25261\n",
      "Mean per-class AUC:0.6774527799245452\n",
      "Epoch 86/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1514 - acc: 0.9371 - val_loss: 0.2564 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.25261\n",
      "Mean per-class AUC:0.7490156170644234\n",
      "Epoch 87/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1491 - acc: 0.9383 - val_loss: 0.2547 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.25261\n",
      "Mean per-class AUC:0.7474293601590964\n",
      "Epoch 88/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1503 - acc: 0.9376 - val_loss: 0.2611 - val_acc: 0.8996\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.25261\n",
      "Mean per-class AUC:0.7423641603504756\n",
      "Epoch 89/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1477 - acc: 0.9398 - val_loss: 0.2791 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.25261\n",
      "Mean per-class AUC:0.6889665425526749\n",
      "Epoch 90/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1484 - acc: 0.9389 - val_loss: 0.2340 - val_acc: 0.9112\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.25261 to 0.23405, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.7385147357343872\n",
      "Epoch 91/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1544 - acc: 0.9366 - val_loss: 0.2940 - val_acc: 0.8986\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.23405\n",
      "Mean per-class AUC:0.6764792949935255\n",
      "Epoch 92/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1485 - acc: 0.9389 - val_loss: 0.2592 - val_acc: 0.9052\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.23405\n",
      "Mean per-class AUC:0.7068691156045871\n",
      "Epoch 93/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1436 - acc: 0.9409 - val_loss: 0.3048 - val_acc: 0.8951\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.23405\n",
      "Mean per-class AUC:0.7146089815873838\n",
      "Epoch 94/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1436 - acc: 0.9402 - val_loss: 0.2667 - val_acc: 0.9011\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.23405\n",
      "Mean per-class AUC:0.7252456025604418\n",
      "Epoch 95/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1481 - acc: 0.9390 - val_loss: 0.2988 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.23405\n",
      "Mean per-class AUC:0.7222551496894168\n",
      "Epoch 96/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1434 - acc: 0.9407 - val_loss: 0.2651 - val_acc: 0.9021\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.23405\n",
      "Mean per-class AUC:0.7209246272935022\n",
      "Epoch 97/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1409 - acc: 0.9421 - val_loss: 0.2320 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.23405 to 0.23200, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.7542416370553514\n",
      "Epoch 98/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1457 - acc: 0.9396 - val_loss: 0.2392 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.23200\n",
      "Mean per-class AUC:0.7224216023085516\n",
      "Epoch 99/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1446 - acc: 0.9400 - val_loss: 0.2488 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.23200\n",
      "Mean per-class AUC:0.7508210581740269\n",
      "Epoch 100/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1402 - acc: 0.9421 - val_loss: 0.3154 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.23200\n",
      "Mean per-class AUC:0.6880863293595363\n",
      "Epoch 101/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1378 - acc: 0.9426 - val_loss: 0.3502 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.23200\n",
      "Mean per-class AUC:0.7181336232911115\n",
      "Epoch 102/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1385 - acc: 0.9430 - val_loss: 0.2608 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.23200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per-class AUC:0.7237685728185912\n",
      "Epoch 103/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1514 - acc: 0.9388 - val_loss: 0.3425 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.23200\n",
      "Mean per-class AUC:0.6645620598732415\n",
      "Epoch 104/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1411 - acc: 0.9417 - val_loss: 0.2751 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.23200\n",
      "Mean per-class AUC:0.7414897542643692\n",
      "Epoch 105/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1357 - acc: 0.9448 - val_loss: 0.2255 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.23200 to 0.22554, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.7441696301117126\n",
      "Epoch 106/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1428 - acc: 0.9412 - val_loss: 0.2338 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.22554\n",
      "Mean per-class AUC:0.7225118901632498\n",
      "Epoch 107/200\n",
      "164/164 [==============================] - 190s 1s/step - loss: 0.1369 - acc: 0.9427 - val_loss: 0.2518 - val_acc: 0.9103\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.22554\n",
      "Mean per-class AUC:0.7080312619600516\n",
      "Epoch 108/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1350 - acc: 0.9451 - val_loss: 0.2693 - val_acc: 0.9002\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.22554\n",
      "Mean per-class AUC:0.7243806166256064\n",
      "Epoch 109/200\n",
      "164/164 [==============================] - 191s 1s/step - loss: 0.1360 - acc: 0.9435 - val_loss: 0.2873 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.22554\n",
      "Mean per-class AUC:0.6973969883218581\n",
      "Epoch 110/200\n",
      "164/164 [==============================] - 205s 1s/step - loss: 0.1318 - acc: 0.9461 - val_loss: 0.2798 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.22554\n",
      "Mean per-class AUC:0.6910171148580363\n",
      "Epoch 111/200\n",
      "164/164 [==============================] - 209s 1s/step - loss: 0.1310 - acc: 0.9460 - val_loss: 0.2253 - val_acc: 0.9163\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.22554 to 0.22531, saving model to models/mobilenet_dense_weights.hdf5\n",
      "Mean per-class AUC:0.756578989125985\n",
      "Epoch 112/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1309 - acc: 0.9456 - val_loss: 0.2601 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7309695992665436\n",
      "Epoch 113/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1306 - acc: 0.9456 - val_loss: 0.2552 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7538953471562084\n",
      "Epoch 114/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1288 - acc: 0.9465 - val_loss: 0.2836 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7216647827229221\n",
      "Epoch 115/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1288 - acc: 0.9466 - val_loss: 0.2622 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7368377738634609\n",
      "Epoch 116/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1233 - acc: 0.9489 - val_loss: 0.2565 - val_acc: 0.9059\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7454101324262686\n",
      "Epoch 117/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1288 - acc: 0.9472 - val_loss: 0.2652 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7290045028114883\n",
      "Epoch 118/200\n",
      "164/164 [==============================] - 212s 1s/step - loss: 0.1264 - acc: 0.9475 - val_loss: 0.2716 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7066286018790597\n",
      "Epoch 119/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1259 - acc: 0.9480 - val_loss: 0.2439 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7381842753746924\n",
      "Epoch 120/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1240 - acc: 0.9488 - val_loss: 0.2549 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.731029202926473\n",
      "Epoch 121/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1276 - acc: 0.9470 - val_loss: 0.3064 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7034912724658275\n",
      "Epoch 122/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1210 - acc: 0.9499 - val_loss: 0.2659 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7403208956979782\n",
      "Epoch 123/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1257 - acc: 0.9478 - val_loss: 0.2337 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7301203450518731\n",
      "Epoch 124/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1195 - acc: 0.9502 - val_loss: 0.2400 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7611150692746352\n",
      "Epoch 125/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1188 - acc: 0.9508 - val_loss: 0.2295 - val_acc: 0.9160\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.755050593701662\n",
      "Epoch 126/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1193 - acc: 0.9504 - val_loss: 0.3060 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7146753809537364\n",
      "Epoch 127/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1199 - acc: 0.9507 - val_loss: 0.2601 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7255267109129956\n",
      "Epoch 128/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1152 - acc: 0.9516 - val_loss: 0.3784 - val_acc: 0.8849\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7180666973983398\n",
      "Epoch 129/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1228 - acc: 0.9490 - val_loss: 0.3250 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.6857260883143805\n",
      "Epoch 130/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1254 - acc: 0.9485 - val_loss: 0.2431 - val_acc: 0.9149\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7345296185225969\n",
      "Epoch 131/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1175 - acc: 0.9509 - val_loss: 0.2913 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7222335006274002\n",
      "Epoch 132/200\n",
      "164/164 [==============================] - 212s 1s/step - loss: 0.1218 - acc: 0.9510 - val_loss: 0.2923 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7215645450693541\n",
      "Epoch 133/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1192 - acc: 0.9509 - val_loss: 0.3320 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7093828399917128\n",
      "Epoch 134/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1133 - acc: 0.9531 - val_loss: 0.3130 - val_acc: 0.8974\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7117083693336274\n",
      "Epoch 135/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1141 - acc: 0.9527 - val_loss: 0.2777 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7257191423858832\n",
      "Epoch 136/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1162 - acc: 0.9512 - val_loss: 0.3491 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.6967132881675057\n",
      "Epoch 137/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1160 - acc: 0.9514 - val_loss: 0.2999 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7117335412456476\n",
      "Epoch 138/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1092 - acc: 0.9549 - val_loss: 0.3040 - val_acc: 0.9019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00138: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.749464379212511\n",
      "Epoch 139/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1096 - acc: 0.9556 - val_loss: 0.2743 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7490849675867935\n",
      "Epoch 140/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1218 - acc: 0.9501 - val_loss: 0.7308 - val_acc: 0.8388\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.576087927757375\n",
      "Epoch 141/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1245 - acc: 0.9483 - val_loss: 0.3363 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.6941947603684462\n",
      "Epoch 142/200\n",
      "164/164 [==============================] - 212s 1s/step - loss: 0.1138 - acc: 0.9534 - val_loss: 0.2948 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7056596794104947\n",
      "Epoch 143/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1079 - acc: 0.9553 - val_loss: 0.3120 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.6891320016076167\n",
      "Epoch 144/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1126 - acc: 0.9539 - val_loss: 0.3082 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.6991701278779262\n",
      "Epoch 145/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1063 - acc: 0.9561 - val_loss: 0.3187 - val_acc: 0.8996\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7149499262590973\n",
      "Epoch 146/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1043 - acc: 0.9568 - val_loss: 0.3086 - val_acc: 0.9013\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7200032839534155\n",
      "Epoch 147/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1066 - acc: 0.9562 - val_loss: 0.2482 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7445240568008852\n",
      "Epoch 148/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1032 - acc: 0.9572 - val_loss: 0.2614 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7194416481290538\n",
      "Epoch 149/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1021 - acc: 0.9581 - val_loss: 0.2355 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7576318696931712\n",
      "Epoch 150/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1107 - acc: 0.9547 - val_loss: 0.4587 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.6179964366081377\n",
      "Epoch 151/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1187 - acc: 0.9509 - val_loss: 0.3106 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7254690595307183\n",
      "Epoch 152/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.1058 - acc: 0.9562 - val_loss: 0.3421 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7139282681278064\n",
      "Epoch 153/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1049 - acc: 0.9577 - val_loss: 0.2856 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.73516787842829\n",
      "Epoch 154/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0986 - acc: 0.9599 - val_loss: 0.2931 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7293555734935606\n",
      "Epoch 155/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.0968 - acc: 0.9604 - val_loss: 0.2583 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.727925072498894\n",
      "Epoch 156/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0976 - acc: 0.9601 - val_loss: 0.2907 - val_acc: 0.9035\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7093986626207357\n",
      "Epoch 157/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.0951 - acc: 0.9608 - val_loss: 0.3841 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.6790937781201557\n",
      "Epoch 158/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0951 - acc: 0.9609 - val_loss: 0.3474 - val_acc: 0.8873\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.714676937259555\n",
      "Epoch 159/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0962 - acc: 0.9610 - val_loss: 0.2553 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7512643382785383\n",
      "Epoch 160/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0969 - acc: 0.9601 - val_loss: 0.3007 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7393771197292129\n",
      "Epoch 161/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0980 - acc: 0.9601 - val_loss: 0.2912 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7326096436579388\n",
      "Epoch 162/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0940 - acc: 0.9612 - val_loss: 0.3912 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.6854055921453078\n",
      "Epoch 163/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.1077 - acc: 0.9557 - val_loss: 0.2772 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7491050147900494\n",
      "Epoch 164/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0943 - acc: 0.9617 - val_loss: 0.2933 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7328002610998875\n",
      "Epoch 165/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0975 - acc: 0.9600 - val_loss: 0.2477 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7647172585891131\n",
      "Epoch 166/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.0899 - acc: 0.9632 - val_loss: 0.2626 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7374020323626951\n",
      "Epoch 167/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0926 - acc: 0.9613 - val_loss: 0.2630 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7588360142499717\n",
      "Epoch 168/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0938 - acc: 0.9617 - val_loss: 0.2541 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7308029324343702\n",
      "Epoch 169/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0971 - acc: 0.9608 - val_loss: 0.2502 - val_acc: 0.9166\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7763082978692516\n",
      "Epoch 170/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.0869 - acc: 0.9650 - val_loss: 0.2973 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7441649160808734\n",
      "Epoch 171/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0928 - acc: 0.9619 - val_loss: 0.3331 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.6996560379529866\n",
      "Epoch 172/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.0879 - acc: 0.9639 - val_loss: 0.2296 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7829420560342047\n",
      "Epoch 173/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.0869 - acc: 0.9645 - val_loss: 0.2689 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7686755653583748\n",
      "Epoch 174/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.0886 - acc: 0.9641 - val_loss: 0.2624 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7561240564858033\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 213s 1s/step - loss: 0.0848 - acc: 0.9665 - val_loss: 0.2474 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7618477853206734\n",
      "Epoch 176/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.0894 - acc: 0.9631 - val_loss: 0.2611 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7558662867485869\n",
      "Epoch 177/200\n",
      "164/164 [==============================] - 214s 1s/step - loss: 0.0818 - acc: 0.9662 - val_loss: 0.2931 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7484533795795518\n",
      "Epoch 178/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0816 - acc: 0.9665 - val_loss: 0.2551 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7722760060005491\n",
      "Epoch 179/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0827 - acc: 0.9659 - val_loss: 0.2945 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7241124996783976\n",
      "Epoch 180/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0853 - acc: 0.9657 - val_loss: 0.2841 - val_acc: 0.9156\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7585290236022338\n",
      "Epoch 181/200\n",
      "164/164 [==============================] - 212s 1s/step - loss: 0.0783 - acc: 0.9680 - val_loss: 0.3380 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7470952168879094\n",
      "Epoch 182/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0869 - acc: 0.9647 - val_loss: 0.2886 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7492497760049944\n",
      "Epoch 183/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0805 - acc: 0.9673 - val_loss: 0.2988 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7569751257398416\n",
      "Epoch 184/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0904 - acc: 0.9634 - val_loss: 0.2562 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.766357277809539\n",
      "Epoch 185/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0751 - acc: 0.9692 - val_loss: 0.2736 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7591054348051369\n",
      "Epoch 186/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0830 - acc: 0.9660 - val_loss: 0.2658 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7728523188821917\n",
      "Epoch 187/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0782 - acc: 0.9682 - val_loss: 0.2757 - val_acc: 0.9146\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7757482285807054\n",
      "Epoch 188/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0869 - acc: 0.9655 - val_loss: 0.2770 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7649080091713544\n",
      "Epoch 189/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0858 - acc: 0.9650 - val_loss: 0.2755 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7563064794650486\n",
      "Epoch 190/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0807 - acc: 0.9672 - val_loss: 0.2781 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7550364125785045\n",
      "Epoch 191/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0843 - acc: 0.9668 - val_loss: 0.3390 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7250097775736702\n",
      "Epoch 192/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0740 - acc: 0.9701 - val_loss: 0.2949 - val_acc: 0.9117\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7243192597814825\n",
      "Epoch 193/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0760 - acc: 0.9695 - val_loss: 0.2710 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7646213719856696\n",
      "Epoch 194/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0726 - acc: 0.9710 - val_loss: 0.3376 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7303749916505518\n",
      "Epoch 195/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0769 - acc: 0.9688 - val_loss: 0.2545 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7835431616988014\n",
      "Epoch 196/200\n",
      "164/164 [==============================] - 212s 1s/step - loss: 0.0717 - acc: 0.9708 - val_loss: 0.2657 - val_acc: 0.9218\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7862857272715318\n",
      "Epoch 197/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0801 - acc: 0.9680 - val_loss: 0.2707 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7782277443998702\n",
      "Epoch 198/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0716 - acc: 0.9715 - val_loss: 0.2602 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7672649636176208\n",
      "Epoch 199/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0699 - acc: 0.9714 - val_loss: 0.3534 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7368753442300968\n",
      "Epoch 200/200\n",
      "164/164 [==============================] - 213s 1s/step - loss: 0.0740 - acc: 0.9701 - val_loss: 0.2883 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.22531\n",
      "Mean per-class AUC:0.7672862874145733\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "        epochs=200,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=STEP_SIZE_VALID,\n",
    "        verbose= 1,\n",
    "        shuffle = True,\n",
    "        callbacks= [tensorboard,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/'+name+'_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
